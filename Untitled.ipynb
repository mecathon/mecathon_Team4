{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "a = numpy.zeros([3, 2])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.]\n",
      " [ 9.  0.]\n",
      " [ 0. 12.]]\n"
     ]
    }
   ],
   "source": [
    "a[0,0] = 1\n",
    "a[0,1] = 2\n",
    "a[1,0] = 9\n",
    "a[2,1] = 12\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n"
     ]
    }
   ],
   "source": [
    "v = a[1, 0]\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21b35f68ac8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "matplotlib.pyplot.imshow(a, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 클래스 정의\n",
    "class neuralNetwork:\n",
    "\n",
    "    # 신경망 초기화 함수\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # 신경망 초기화에 필요한 각 변수 설정\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "\n",
    "        #학습률 설정\n",
    "        self.lr = learningrate\n",
    "        pass\n",
    "\n",
    "    # 신경망 훈련 함수\n",
    "    def train():\n",
    "        pass\n",
    "\n",
    "    # 신경망 질문 함수\n",
    "    def query():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 입력, 은닉, 출력 노드 수 설정\n",
    "input_nodes = 3\n",
    "hidden_nodes = 3\n",
    "output_nodes = 3\n",
    "\n",
    "# 학습률 값 설정\n",
    "learning_rate = 0.3\n",
    "\n",
    "# 신경망 인스턴스 생성\n",
    "n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.19929604, -0.28758511,  0.11629304],\n",
       "       [ 0.33839141,  0.08341147,  0.46561489],\n",
       "       [ 0.13413965, -0.10131596,  0.08627298]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.random.rand(3,3) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "#시그모이드 함수 expit() 을 사용하기 위한 scipy.special 임포트\n",
    "import scipy.special\n",
    "\n",
    "# 신경망 클래스 정의\n",
    "class neuralNetwork:\n",
    "\n",
    "    # 신경망 초기화 함수\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # 신경망 초기화에 필요한 각 변수 설정\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "\n",
    "        # 노드 i 와 다음 층의 노드 j 를 연결하는 가중치 w_i_j\n",
    "        self.wih = (numpy.random.rand(self.hnodes, self.inodes) - 0.5)\n",
    "        self.who = (numpy.random.rand(self.inodes, self.onodes) - 0.5) \n",
    "\n",
    "        #학습률 설정\n",
    "        self.lr = learningrate\n",
    "\n",
    "        #활성화 함수는 시그모이드 함수 사용\n",
    "        self.activation_function = lambda x : scipy.special.expit(x)\n",
    "        pass\n",
    "\n",
    "    # 신경망 훈련 함수\n",
    "    def train():\n",
    "        pass\n",
    "\n",
    "    # 신경망 질문 함수\n",
    "    def query(self, inputs_list):\n",
    "\n",
    "        #리스트를 2차원 행렬로 변환\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "\n",
    "        # 은닉층 입력값 = 가중치(Wih)와 input 값의 행렬곱\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        #은닉층으로부터 나오는 신호 계산\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "\n",
    "        # 출력층 입력값 = 가중치(Who) 와 hidden_output 의 행렬곱\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        #출력층으로부터 나오는 신호 계산\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력, 은닉, 출력 노드 수 설정\n",
    "input_nodes = 3\n",
    "hidden_nodes = 3\n",
    "output_nodes = 3\n",
    "\n",
    "# 학습률 값 설정\n",
    "learning_rate = 0.3\n",
    "\n",
    "# 신경망 인스턴스 생성\n",
    "n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53625647],\n",
       "       [0.61690672],\n",
       "       [0.54709908]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.query([1.0, 0.5, -1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file= open(\"C:/Users/Blueberry/Desktop/neuralNetwork/mnist_train_100.csv\", 'r')\n",
    "data_list= data_file.readlines()\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,67,232,39,0,0,0,0,0,0,0,0,0,62,81,0,0,0,0,0,0,0,0,0,0,0,0,0,0,120,180,39,0,0,0,0,0,0,0,0,0,126,163,0,0,0,0,0,0,0,0,0,0,0,0,0,2,153,210,40,0,0,0,0,0,0,0,0,0,220,163,0,0,0,0,0,0,0,0,0,0,0,0,0,27,254,162,0,0,0,0,0,0,0,0,0,0,222,163,0,0,0,0,0,0,0,0,0,0,0,0,0,183,254,125,0,0,0,0,0,0,0,0,0,46,245,163,0,0,0,0,0,0,0,0,0,0,0,0,0,198,254,56,0,0,0,0,0,0,0,0,0,120,254,163,0,0,0,0,0,0,0,0,0,0,0,0,23,231,254,29,0,0,0,0,0,0,0,0,0,159,254,120,0,0,0,0,0,0,0,0,0,0,0,0,163,254,216,16,0,0,0,0,0,0,0,0,0,159,254,67,0,0,0,0,0,0,0,0,0,14,86,178,248,254,91,0,0,0,0,0,0,0,0,0,0,159,254,85,0,0,0,47,49,116,144,150,241,243,234,179,241,252,40,0,0,0,0,0,0,0,0,0,0,150,253,237,207,207,207,253,254,250,240,198,143,91,28,5,233,250,0,0,0,0,0,0,0,0,0,0,0,0,119,177,177,177,177,177,98,56,0,0,0,0,0,102,254,220,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,169,254,137,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,169,254,57,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,169,254,57,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,169,255,94,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,169,254,96,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,169,254,153,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,169,255,153,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,96,254,153,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21b3654df98>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_values = data_list[2].split(',')\n",
    "image_array = numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "matplotlib.pyplot.imshow(image_array, cmap = 'Greys', interpolation = 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.27011765 0.91070588\n",
      " 0.16141176 0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.25070588 0.32447059\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.47588235 0.70882353 0.16141176 0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.49917647 0.64282353 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01776471\n",
      " 0.604      0.82529412 0.16529412 0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.86411765 0.64282353 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.11482353 0.99611765 0.63894118\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.87188235 0.64282353\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.72047059 0.99611765 0.49529412 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.18858824 0.96117647 0.64282353 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.77870588\n",
      " 0.99611765 0.22741176 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.47588235\n",
      " 0.99611765 0.64282353 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.09929412 0.90682353 0.99611765 0.12258824\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.62729412 0.99611765 0.47588235\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.64282353 0.99611765 0.84858824 0.07211765 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.62729412 0.99611765 0.27011765 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.06435294 0.34388235 0.70105882 0.97282353 0.99611765\n",
      " 0.36329412 0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.62729412\n",
      " 0.99611765 0.34       0.01       0.01       0.01       0.19247059\n",
      " 0.20023529 0.46035294 0.56905882 0.59235294 0.94564706 0.95341176\n",
      " 0.91847059 0.70494118 0.94564706 0.98835294 0.16529412 0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.59235294 0.99223529 0.93011765\n",
      " 0.81364706 0.81364706 0.81364706 0.99223529 0.99611765 0.98058824\n",
      " 0.94176471 0.77870588 0.56517647 0.36329412 0.11870588 0.02941176\n",
      " 0.91458824 0.98058824 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.472      0.69717647 0.69717647 0.69717647\n",
      " 0.69717647 0.69717647 0.39047059 0.22741176 0.01       0.01\n",
      " 0.01       0.01       0.01       0.406      0.99611765 0.86411765\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.66611765 0.99611765 0.54188235 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.66611765\n",
      " 0.99611765 0.23129412 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.66611765 0.99611765 0.23129412\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.66611765 1.         0.37494118 0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.66611765\n",
      " 0.99611765 0.38270588 0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.66611765 0.99611765 0.604\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.66611765 1.         0.604      0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.38270588\n",
      " 0.99611765 0.604      0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01       0.01       0.01\n",
      " 0.01       0.01       0.01       0.01      ]\n"
     ]
    }
   ],
   "source": [
    "scaled_input = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "print(scaled_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "#시그모이드 함수 expit() 을 사용하기 위한 scipy.special 임포트\n",
    "import scipy.special\n",
    "\n",
    "# 신경망 클래스 정의\n",
    "class neuralNetwork:\n",
    "\n",
    "    # 신경망 초기화 함수\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # 신경망 초기화에 필요한 각 변수 설정\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "\n",
    "        # 노드 i 와 다음 층의 노드 j 를 연결하는 가중치 w_i_j\n",
    "        self.wih = (numpy.random.rand(self.hnodes, self.inodes) - 0.5)\n",
    "        self.who = (numpy.random.rand(self.inodes, self.onodes) - 0.5) \n",
    "\n",
    "        #학습률 설정\n",
    "        self.lr = learningrate\n",
    "\n",
    "        #활성화 함수는 시그모이드 함수 사용\n",
    "        self.activation_function = lambda x : scipy.special.expit(x)\n",
    "        pass\n",
    "\n",
    "    # 신경망 훈련 함수\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        #리스트를 2차원 행렬로 변환\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "\n",
    "        # 은닉층 입력값 = 가중치(Wih)와 input 값의 행렬곱\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        #은닉층으로부터 나오는 신호 계산\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "\n",
    "        # 출력층 입력값 = 가중치(Who) 와 hidden_output 의 행렬곱\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        #출력층으로부터 나오는 신호 계산\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "\n",
    "        # 최종 오차 = 최종 결과 - 정답(target)\n",
    "        output_errors = targets - final_outputs\n",
    "        # 은닉층 오차 = 최종 오차 * 가중치\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors)\n",
    "\n",
    "        # 은닉층과 출력층 사이 가중치 오차 역전파 코드\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0- final_outputs)), numpy.transpose(hidden_outputs))\n",
    "\n",
    "        # 입력층과 은닉층 사이 가중치 오차 역전파 코드\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "\n",
    "        pass\n",
    "\n",
    "    # 신경망 질문 함수\n",
    "    def query(self, inputs_list):\n",
    "\n",
    "        #리스트를 2차원 행렬로 변환\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "\n",
    "        # 은닉층 입력값 = 가중치(Wih)와 input 값의 행렬곱\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        #은닉층으로부터 나오는 신호 계산\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "\n",
    "        # 출력층 입력값 = 가중치(Who) 와 hidden_output 의 행렬곱\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        #출력층으로부터 나오는 신호 계산\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "\n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력, 은닉, 출력 노드 수 설정\n",
    "input_nodes = 784\n",
    "hidden_nodes = 100\n",
    "output_nodes = 10\n",
    "\n",
    "# 학습률 값 설정\n",
    "learning_rate = 0.3\n",
    "\n",
    "# 신경망 인스턴스 생성\n",
    "n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "\n",
    "# 훈련 데이터 불러오기 & 리스트화\n",
    "training_data_file = open(\"C:/Users/Blueberry/Desktop/neuralNetwork/mnist_train_100.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (784,10) and (100,1) not aligned: 10 (dim 1) != 100 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-c71ed35ca83e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# 정답(각 입력 리스트의 0번째 값) 과 출력값 비교\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.99\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-56039fd9e0b0>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, inputs_list, targets_list)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;31m# 출력층 입력값 = 가중치(Who) 와 hidden_output 의 행렬곱\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mfinal_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwho\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;31m#출력층으로부터 나오는 신호 계산\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mfinal_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (784,10) and (100,1) not aligned: 10 (dim 1) != 100 (dim 0)"
     ]
    }
   ],
   "source": [
    "# 신경망 훈련\n",
    "\n",
    "# go through all records in the training data set\n",
    "for record in training_data_list:\n",
    "    # ',' 를 기준으로 각 레코드를 스플릿.\n",
    "    all_values = record.split(',')\n",
    "    # 입력값을 0.01~1.0 사이에 위치하도록 변환\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # 목표 출력값 생성\n",
    "    targets = numpy.zeros(output_nodes) + 0.01\n",
    "    # 정답(각 입력 리스트의 0번째 값) 과 출력값 비교\n",
    "    targets[int(all_values[0])] = 0.99\n",
    "    n.train(inputs, targets)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (784,10) and (100,1) not aligned: 10 (dim 1) != 100 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-162aeb1302e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;31m# all_values[0] is the target label for this record\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.99\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m     \u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-52-162aeb1302e2>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, inputs_list, targets_list)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mhidden_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;31m# calculate signals into final output layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mfinal_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwho\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[1;31m# calculate the signals emerging from final output layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mfinal_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (784,10) and (100,1) not aligned: 10 (dim 1) != 100 (dim 0)"
     ]
    }
   ],
   "source": [
    "# python notebook for Make Your Own Neural Network\n",
    "# code for a 3-layer neural network, and code for learning the MNIST dataset\n",
    "# (c) Tariq Rashid, 2016\n",
    "# license is GPLv2\n",
    "import numpy\n",
    "# scipy.special for the sigmoid function expit()\n",
    "import scipy.special\n",
    "# library for plotting arrays\n",
    "import matplotlib.pyplot\n",
    "# ensure the plots are inside this notebook, not an external window\n",
    "%matplotlib inline\n",
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "# initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes,learningrate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        # link weight matrices, wih and who\n",
    "        # weights inside the arrays are w_i_j, where link is fromnode i to node j in the next layer\n",
    "        # w11 w21\n",
    "        # w12 w22 etc\n",
    "        self.wih = (numpy.random.rand(self.hnodes, self.inodes) - 0.5)\n",
    "        self.who = (numpy.random.rand(self.inodes, self.onodes) - 0.5) \n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        pass\n",
    "\n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights,recombined at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors)\n",
    "        # update the weights for the links between the hidden andoutput layers\n",
    "        self.who += self.lr * numpy.dot((output_errors *final_outputs * (1.0 - final_outputs)),numpy.transpose(hidden_outputs))\n",
    "        # update the weights for the links between the input andhidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors *hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        pass\n",
    "\n",
    "# query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        return final_outputs\n",
    "\n",
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 100\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate is 0.3\n",
    "learning_rate = 0.3\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes,learning_rate)\n",
    "\n",
    "# load the mnist training data CSV file into a list\n",
    "training_data_file = open(\"C:/Users/Blueberry/Desktop/neuralNetwork/mnist_train_100.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()\n",
    "\n",
    "# train the neural network\n",
    "# go through all records in the training data set\n",
    "for record in training_data_list:\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # scale and shift the inputs\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # create the target output values (all 0.01, except the desiredlabel which is 0.99)\n",
    "    targets = numpy.zeros(output_nodes) + 0.01\n",
    "    # all_values[0] is the target label for this record\n",
    "    targets[int(all_values[0])] = 0.99\n",
    "    n.train(inputs, targets)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "# scipy.special for the sigmoid function expit()\n",
    "import scipy.special\n",
    "# library for plotting arrays\n",
    "import matplotlib.pyplot\n",
    "# ensure the plots are inside this notebook, not an external window\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    \n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # link weight matrices, wih and who\n",
    "        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n",
    "        # w11 w21\n",
    "        # w12 w22 etc \n",
    "        \n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors) \n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist training data CSV file into a list\n",
    "training_data_file = open(\"C:/Users/Blueberry/Desktop/neuralNetwork/mnist_train_100.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (784,10) and (200,1) not aligned: 10 (dim 1) != 200 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-fbb9efa932ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# all_values[0] is the target label for this record\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.99\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-60-2cbc16043fc1>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, inputs_list, targets_list)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m# calculate signals into final output layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mfinal_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwho\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[1;31m# calculate the signals emerging from final output layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mfinal_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (784,10) and (200,1) not aligned: 10 (dim 1) != 200 (dim 0)"
     ]
    }
   ],
   "source": [
    "for record in training_data_list:\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "        # scale and shift the inputs\n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralNetwork:\n",
    "\n",
    "    # 신경망 초기화 함수\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # 신경망 초기화에 필요한 각 변수 설정\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "\n",
    "        # 노드 i 와 다음 층의 노드 j 를 연결하는 가중치 w_i_j\n",
    "        self.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
    "        #학습률 설정\n",
    "        self.lr = learningrate\n",
    "\n",
    "        #활성화 함수는 시그모이드 함수 사용\n",
    "        self.activation_function = lambda x : scipy.special.expit(x)\n",
    "        pass\n",
    "\n",
    "    # 신경망 훈련 함수\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        #리스트를 2차원 행렬로 변환\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "\n",
    "        # 은닉층 입력값 = 가중치(Wih)와 input 값의 행렬곱\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        #은닉층으로부터 나오는 신호 계산\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "\n",
    "        # 출력층 입력값 = 가중치(Who) 와 hidden_output 의 행렬곱\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        #출력층으로부터 나오는 신호 계산\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "\n",
    "        # 최종 오차 = 최종 결과 - 정답(target)\n",
    "        output_errors = targets - final_outputs\n",
    "        # 은닉층 오차 = 최종 오차 * 가중치\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors)\n",
    "\n",
    "        # 은닉층과 출력층 사이 가중치 오차 역전파 코드\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0- final_outputs)), numpy.transpose(hidden_outputs))\n",
    "\n",
    "        # 입력층과 은닉층 사이 가중치 오차 역전파 코드\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "\n",
    "        pass\n",
    "\n",
    "    # 신경망 질문 함수\n",
    "    def query(self, inputs_list):\n",
    "\n",
    "        #리스트를 2차원 행렬로 변환\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "\n",
    "        # 은닉층 입력값 = 가중치(Wih)와 input 값의 행렬곱\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        #은닉층으로부터 나오는 신호 계산\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "\n",
    "        # 출력층 입력값 = 가중치(Who) 와 hidden_output 의 행렬곱\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        #출력층으로부터 나오는 신호 계산\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "\n",
    "        return final_outputs\n",
    "        \n",
    "\n",
    "\n",
    "# 입력, 은닉, 출력 노드 수 설정\n",
    "input_nodes = 784\n",
    "hidden_nodes = 300\n",
    "output_nodes = 10\n",
    "\n",
    "# 학습률 값 설정\n",
    "learning_rate = 0.35\n",
    "\n",
    "# 신경망 인스턴스 생성\n",
    "n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "\n",
    "# 훈련 데이터 불러오기 & 리스트화\n",
    "training_data_file = open(\"C:/Users/Blueberry/Desktop/neuralNetwork/mnist_train.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()\n",
    "\n",
    "\n",
    "# 신경망 훈련\n",
    "\n",
    "# go through all records in the training data set\n",
    "for record in training_data_list:\n",
    "    # ',' 를 기준으로 각 레코드를 스플릿.\n",
    "    all_values = record.split(',')\n",
    "    # 입력값을 0.01~1.0 사이에 위치하도록 변환\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # 목표 출력값 생성\n",
    "    targets = numpy.zeros(output_nodes) + 0.01\n",
    "    # 정답(각 입력 리스트의 0번째 값) 과 출력값 비교\n",
    "    targets[int(all_values[0])] = 0.99\n",
    "    n.train(inputs, targets)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 불러오기 & 리스트화\n",
    "test_data_file = open(\"C:/Users/Blueberry/Desktop/neuralNetwork/mnist_test.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test the neural network\n",
    "\n",
    "# scorecard for how well the network performs, initially empty\n",
    "scorecard = []\n",
    "\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list:\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    # scale and shift the inputs\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = numpy.argmax(outputs)\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.9511\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance score, the fraction of correct answers\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "print (\"performance = \", scorecard_array.sum() / scorecard_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
